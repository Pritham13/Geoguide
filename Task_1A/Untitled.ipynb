{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aac2b02a-9575-4910-b37b-e2724420285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "158e395d-5463-4f00-99c3-d45525fc0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf296cf-8ce7-4809-9ab1-8b7caa086500",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1a_dataframe = pandas.read_csv('task_1a_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58b3eb9-04f5-4eb7-80d6-ad2aa5b7c994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2012</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  JoiningYear       City  PaymentTier  Age Gender EverBenched  \\\n",
       "0  Bachelors         2012  Bangalore            3   37   Male          No   \n",
       "1    Masters         2017  New Delhi            2   28   Male          No   \n",
       "2  Bachelors         2017  New Delhi            2   36   Male          No   \n",
       "3  Bachelors         2015  Bangalore            3   27   Male         Yes   \n",
       "4  Bachelors         2017  Bangalore            3   29   Male          No   \n",
       "\n",
       "   ExperienceInCurrentDomain  LeaveOrNot  \n",
       "0                          0           0  \n",
       "1                          4           0  \n",
       "2                          3           0  \n",
       "3                          5           0  \n",
       "4                          4           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = task_1a_dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd97276-7360-449a-a2fa-2d97469737aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education                    0\n",
       "JoiningYear                  0\n",
       "City                         0\n",
       "PaymentTier                  0\n",
       "Age                          0\n",
       "Gender                       0\n",
       "EverBenched                  0\n",
       "ExperienceInCurrentDomain    0\n",
       "LeaveOrNot                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c06d1ff-008d-429d-a26f-b9e8b61f5ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      JoiningYear  City  Age  Gender  EverBenched  ExperienceInCurrentDomain  \\\n",
      "0               0     0   15       1            0                          0   \n",
      "1               5     1    6       1            0                          4   \n",
      "2               5     1   14       1            0                          3   \n",
      "3               3     0    5       1            1                          5   \n",
      "4               5     0    7       1            0                          4   \n",
      "...           ...   ...  ...     ...          ...                        ...   \n",
      "4628            1     0    4       0            0                          4   \n",
      "4629            1     2   15       1            0                          2   \n",
      "4630            6     1    5       1            0                          5   \n",
      "4631            0     0    8       1            1                          2   \n",
      "4632            3     0   11       1            1                          4   \n",
      "\n",
      "      LeaveOrNot  Education_Bachelors  Education_Masters  Education_PHD  \\\n",
      "0              0                    1                  0              0   \n",
      "1              0                    0                  1              0   \n",
      "2              0                    1                  0              0   \n",
      "3              0                    1                  0              0   \n",
      "4              0                    1                  0              0   \n",
      "...          ...                  ...                ...            ...   \n",
      "4628           0                    1                  0              0   \n",
      "4629           1                    0                  1              0   \n",
      "4630           1                    0                  1              0   \n",
      "4631           0                    1                  0              0   \n",
      "4632           0                    1                  0              0   \n",
      "\n",
      "      PaymentTier_1  PaymentTier_2  PaymentTier_3  \n",
      "0                 0              0              1  \n",
      "1                 0              1              0  \n",
      "2                 0              1              0  \n",
      "3                 0              0              1  \n",
      "4                 0              0              1  \n",
      "...             ...            ...            ...  \n",
      "4628              0              0              1  \n",
      "4629              0              1              0  \n",
      "4630              0              0              1  \n",
      "4631              0              0              1  \n",
      "4632              0              0              1  \n",
      "\n",
      "[4633 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "# List of categorical columns to one-hot encode\n",
    "categorical_columns = ['Education', 'PaymentTier']\n",
    "\n",
    "# Apply one-hot encoding to all categorical columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "# Encode binary categorical columns ('Gender', 'EverBenched', 'LeaveOrNot') using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "binary_categorical_columns = ['Age', 'JoiningYear', 'City', 'Gender', 'EverBenched', 'LeaveOrNot']\n",
    "for column in binary_categorical_columns:\n",
    "    df_encoded[column] = label_encoder.fit_transform(df_encoded[column])\n",
    "\n",
    "# Display the encoded DataFrame\n",
    "df_encoded = df_encoded.astype(int)\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bb0c77e-8fc4-41e3-ac7e-33da85a9e435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['JoiningYear', 'City', 'Age', 'Gender', 'EverBenched',\n",
       "       'ExperienceInCurrentDomain', 'LeaveOrNot', 'Education_Bachelors',\n",
       "       'Education_Masters', 'Education_PHD', 'PaymentTier_1', 'PaymentTier_2',\n",
       "       'PaymentTier_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56fc3093-1e6f-47a5-b605-b0c9c3d4593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(task_1a_dataframe):\n",
    "    df = task_1a_dataframe\n",
    "\n",
    "    \n",
    "\n",
    "    # Assuming your DataFrame is named 'df'\n",
    "    # List of categorical columns to one-hot encode\n",
    "    categorical_columns = ['Education', 'PaymentTier']\n",
    "    \n",
    "    # Apply one-hot encoding to all categorical columns\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_columns)\n",
    "    \n",
    "    # Encode binary categorical columns ('Gender', 'EverBenched', 'LeaveOrNot') using LabelEncoder\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    binary_categorical_columns = ['Age', 'JoiningYear', 'City', 'Gender', 'EverBenched', 'LeaveOrNot']\n",
    "    for column in binary_categorical_columns:\n",
    "        df_encoded[column] = label_encoder.fit_transform(df_encoded[column])\n",
    "    \n",
    "    # Display the encoded DataFrame\n",
    "    df_encoded = df_encoded.astype(int)\n",
    "    \n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5a54de8-bc2b-4e54-9730-09d469641c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4633, 13)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec1d3746-6888-4325-b4f2-39bddb3bd392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_features_and_targets(encoded_dataframe):\n",
    "    features = encoded_dataframe.drop(columns=['LeaveOrNot'])\n",
    "    target = encoded_dataframe['LeaveOrNot']\n",
    "\n",
    "    features_and_targets = [features, target]\n",
    "\n",
    "    return features_and_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b3c783e-f0cc-425a-acf1-2857ecc8df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_as_tensors(features_and_targets):\n",
    "    [X, y] = features_and_targets\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "    y_test_tensor = torch.LongTensor(y_test)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    batch_size = 32  # You can adjust the batch size as needed\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    tensors_and_iterable_training_data = [X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, train_loader]\n",
    "\n",
    "    return tensors_and_iterable_training_data\n",
    "\n",
    "# Example usage:\n",
    "# features_and_targets = [X, y]  # Replace X and y with your actual data\n",
    "# tensors_and_iterable_training_data = load_as_tensors(features_and_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2b4d4ba-5c17-40d3-ba4d-e8290f71a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Salary_Predictor(nn.Module):\n",
    "    def __init__(self, input_features=12, hidden1=20, hidden2=20, output_features=2):\n",
    "        super(Salary_Predictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_features, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "522145c2-597f-499b-a2ee-6437bc68a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss_function():\n",
    "    '''\n",
    "    Define the loss function for the model\n",
    "    '''\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    return loss_function\n",
    "def model_optimizer(model):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01) #learning rate\n",
    "    return optimizer\n",
    "\n",
    "def model_number_of_epochs():\n",
    "    number_of_epochs=30\n",
    "    return number_of_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6a372cf-6582-49d4-8f2c-b25a85353861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(model, number_of_epochs, tensors_and_iterable_training_data, loss_function, optimizer):\n",
    "    training_data = TensorDataset(tensors_and_iterable_training_data[0],tensors_and_iterable_training_data[2])\n",
    "    training_loader = torch.utils.data.DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "\n",
    "    #validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=64, shuffle=True)\n",
    "    for epoch in range(number_of_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(training_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # print(i)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            inputs = inputs.float() #converting into float \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs.squeeze(), labels)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            average_loss = running_loss / len(training_loader)\n",
    "        \n",
    "        # Print epoch-wise loss\n",
    "        print(f\"Epoch {epoch+1}/{number_of_epochs}: Loss = {average_loss}\")\n",
    "            # if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            #     print('[%d, %5d] loss: %.3f' %\n",
    "            #           (epoch + 1, i + 1, running_loss / 2000))\n",
    "            #     running_loss = 0.0\n",
    "    return model\n",
    "\n",
    "def validation_function(trained_model, tensors_and_iterable_training_data):\n",
    "    # Set the model to evaluation mode\n",
    "    trained_model.eval()\n",
    "\n",
    "    # Unpack the input arguments\n",
    "    validation_data = tensors_and_iterable_training_data[1]\n",
    "    validation_labels = tensors_and_iterable_training_data[3]\n",
    "    # validation_dataset = torch.utils.data.DataLoader(validation_data, batch_size=64, shuffle=True)\n",
    "    # validation_data, validation_labels, validation_dataset = tensors_and_iterable_training_data\n",
    "\n",
    "    # Create a DataLoader for the validation dataset\n",
    "    # validation_loader = torch.utils.data.DataLoader(validation_dataset)\n",
    "\n",
    "    # Move the validation data to the device (e.g., GPU) if available\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # validation_data = validation_data.to(device)\n",
    "    # validation_labels = validation_labels.to(device)\n",
    "\n",
    "    # Calculate the predictions of the trained model on the validation data\n",
    "    with torch.no_grad():\n",
    "        predictions = trained_model(validation_data)\n",
    "\n",
    "    # Convert the predicted probabilities to class labels\n",
    "    _, predicted_labels = torch.max(predictions, 1)\n",
    "\n",
    "    # Calculate the accuracy of the model\n",
    "    correct_predictions = (predicted_labels == validation_labels).sum().item()\n",
    "    total_predictions = len(validation_labels)\n",
    "    model_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887794c-f940-4cf2-b907-4a9c43828c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(model, number_of_epochs, tensors_and_iterable_training_data, loss_function, optimizer):\n",
    "\t'''\n",
    "\tPurpose:\n",
    "\t---\n",
    "\tAll the required parameters for training are passed to this function.\n",
    "\n",
    "\tInput Arguments:\n",
    "\t---\n",
    "\t1. `model`: An object of the 'Salary_Predictor' class\n",
    "\t2. `number_of_epochs`: For training the model\n",
    "\t3. `tensors_and_iterable_training_data`: list containing training and validation data tensors \n",
    "\t\t\t\t\t\t\t\t\t\t\t and iterable dataset object of training tensors\n",
    "\t4. `loss_function`: Loss function defined for the model\n",
    "\t5. `optimizer`: Optimizer defined for the model\n",
    "\n",
    "\tReturns:\n",
    "\t---\n",
    "\ttrained_model\n",
    "\n",
    "\tExample call:\n",
    "\t---\n",
    "\ttrained_model = training_function(model, number_of_epochs, iterable_training_data, loss_function, optimizer)\n",
    "\n",
    "\t'''\t\n",
    "\t#################\tADD YOUR CODE HERE\t##################\n",
    "\t\n",
    "\t##########################################################\n",
    "\n",
    "\treturn trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378bb46-21b0-4453-b15a-c316ba5e1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_function(trained_model, tensors_and_iterable_training_data):\n",
    "\t'''\n",
    "\tPurpose:\n",
    "\t---\n",
    "\tThis function will utilise the trained model to do predictions on the\n",
    "\tvalidation dataset. This will enable us to understand the accuracy of\n",
    "\tthe model.\n",
    "\n",
    "\tInput Arguments:\n",
    "\t---\n",
    "\t1. `trained_model`: Returned from the training function\n",
    "\t2. `tensors_and_iterable_training_data`: list containing training and validation data tensors \n",
    "\t\t\t\t\t\t\t\t\t\t\t and iterable dataset object of training tensors\n",
    "\n",
    "\tReturns:\n",
    "\t---\n",
    "\tmodel_accuracy: Accuracy on the validation dataset\n",
    "\n",
    "\tExample call:\n",
    "\t---\n",
    "\tmodel_accuracy = validation_function(trained_model, tensors_and_iterable_training_data)\n",
    "\n",
    "\t'''\t\n",
    "\t#################\tADD YOUR CODE HERE\t##################\n",
    "\n",
    "\t##########################################################\n",
    "\n",
    "\treturn model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fc11e63-2416-48f5-8f26-c0c73ae5dad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: Loss = 0.6024387494243425\n",
      "Epoch 2/30: Loss = 0.5663721494633576\n",
      "Epoch 3/30: Loss = 0.5396126488159443\n",
      "Epoch 4/30: Loss = 0.5037316808412815\n",
      "Epoch 5/30: Loss = 0.48391943861698283\n",
      "Epoch 6/30: Loss = 0.4782300067359003\n",
      "Epoch 7/30: Loss = 0.4742654757253055\n",
      "Epoch 8/30: Loss = 0.4573420692106773\n",
      "Epoch 9/30: Loss = 0.4460906622738674\n",
      "Epoch 10/30: Loss = 0.4292291896096591\n",
      "Epoch 11/30: Loss = 0.4269201760662013\n",
      "Epoch 12/30: Loss = 0.41386535609590597\n",
      "Epoch 13/30: Loss = 0.3973549275562681\n",
      "Epoch 14/30: Loss = 0.3993378109459219\n",
      "Epoch 15/30: Loss = 0.3919782628273142\n",
      "Epoch 16/30: Loss = 0.38639904610041914\n",
      "Epoch 17/30: Loss = 0.38489997412624033\n",
      "Epoch 18/30: Loss = 0.3823326990522187\n",
      "Epoch 19/30: Loss = 0.37534348127143136\n",
      "Epoch 20/30: Loss = 0.37442590733026637\n",
      "Epoch 21/30: Loss = 0.3681092768393714\n",
      "Epoch 22/30: Loss = 0.3729730888173498\n",
      "Epoch 23/30: Loss = 0.3693984834284618\n",
      "Epoch 24/30: Loss = 0.36708910917413645\n",
      "Epoch 25/30: Loss = 0.3616923191424074\n",
      "Epoch 26/30: Loss = 0.3630948852876137\n",
      "Epoch 27/30: Loss = 0.3596411632566616\n",
      "Epoch 28/30: Loss = 0.3620755397554102\n",
      "Epoch 29/30: Loss = 0.36364261009569826\n",
      "Epoch 30/30: Loss = 0.3588936202998819\n",
      "Accuracy on the test set = 0.8468176914778857\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "\t# reading the provided dataset csv file using pandas library and \n",
    "\t# converting it to a pandas Dataframe\n",
    "\ttask_1a_dataframe = pandas.read_csv('task_1a_dataset.csv')\n",
    "\n",
    "\t# data preprocessing and obtaining encoded data\n",
    "\tencoded_dataframe = data_preprocessing(task_1a_dataframe)\n",
    "\n",
    "\t# selecting required features and targets\n",
    "\tfeatures_and_targets = identify_features_and_targets(encoded_dataframe)\n",
    "\n",
    "\t# obtaining training and validation data tensors and the iterable\n",
    "\t# training data object\n",
    "\ttensors_and_iterable_training_data = load_as_tensors(features_and_targets)\n",
    "\t\n",
    "\t# model is an instance of the class that defines the architecture of the model\n",
    "\tmodel = Salary_Predictor()\n",
    "\n",
    "\t# obtaining loss function, optimizer and the number of training epochs\n",
    "\tloss_function = model_loss_function()\n",
    "\toptimizer = model_optimizer(model)\n",
    "\tnumber_of_epochs = model_number_of_epochs()\n",
    "\n",
    "\t# training the model\n",
    "\ttrained_model = training_function(model, number_of_epochs, tensors_and_iterable_training_data, \n",
    "\t\t\t\t\tloss_function, optimizer)\n",
    "\n",
    "\t# validating and obtaining accuracy\n",
    "\tmodel_accuracy = validation_function(trained_model,tensors_and_iterable_training_data)\n",
    "\tprint(f\"Accuracy on the test set = {model_accuracy}\")\n",
    "\n",
    "\tX_train_tensor = tensors_and_iterable_training_data[0]\n",
    "\tx = X_train_tensor[0]\n",
    "\tjitted_model = torch.jit.save(torch.jit.trace(model, (x)), \"task_1a_trained_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1065ab-d0a5-417e-a19c-30538a519412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
